{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLLNzD_k8b_T",
        "outputId": "33f47200-30e0-4613-deb4-42eb9e2fd952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.4.1\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark==3.4.1) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285391 sha256=796d6a2f041d0fb4b11f4682b8fc24859444b31bf320b6d46c9d006156bf5fb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/b4/d8/38accc42606f6675165423e9f0236f8e825f6b6b6048d6743e\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.5.1\n",
            "    Uninstalling pyspark-3.5.1:\n",
            "      Successfully uninstalled pyspark-3.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.3 requires pyspark[connect]~=3.5.1, but you have pyspark 3.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyspark-3.4.1\n",
            "Collecting spark-nlp==5.2.3\n",
            "  Downloading spark_nlp-5.2.3-py2.py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spark_nlp-5.2.3-py2.py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.6/547.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-5.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.4.1\n",
        "!pip install spark-nlp==5.2.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from sparknlp.base import DocumentAssembler, Pipeline\n",
        "from sparknlp.annotator import Tokenizer, Normalizer, BertEmbeddings, SentimentDLModel, LemmatizerModel, UniversalSentenceEncoder\n",
        "from pyspark.ml import Pipeline as MLPipeline\n",
        "\n",
        "# Start Spark NLP session\n",
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "# Sample dataset (50 sample sentences)\n",
        "sentences = [\n",
        "    \"I love this movie!\", \"This was the worst experience.\", \"Pretty decent overall.\",\n",
        "    \"Absolutely fantastic!\", \"I'm not sure how I feel.\", \"Worst purchase ever.\",\n",
        "    \"Great value for the money.\", \"It was okay, not great.\", \"Terrible, just terrible.\",\n",
        "    \"Super fun and engaging!\", \"Would not recommend it.\", \"Kind of boring.\",\n",
        "    \"Loved every minute!\", \"It was a disaster.\", \"Highly recommend!\",\n",
        "    \"Too expensive for what you get.\", \"Amazing support team!\", \"Horrible food.\",\n",
        "    \"I'll definitely buy it again.\", \"Meh, nothing special.\", \"Exceeded my expectations!\",\n",
        "    \"Not worth the hype.\", \"Incredible storytelling.\", \"Never again.\",\n",
        "    \"Pretty enjoyable!\", \"Worst customer service.\", \"Delightful and fresh.\",\n",
        "    \"Disappointed.\", \"Can't wait to try it again!\", \"A total waste of time.\",\n",
        "    \"Superb work!\", \"Very underwhelming.\", \"Loved the packaging.\",\n",
        "    \"Felt very rushed.\", \"Unbelievably good.\", \"Didn't like it at all.\",\n",
        "    \"Perfect execution!\", \"Mediocre at best.\", \"Simply amazing.\",\n",
        "    \"It made my day!\", \"Forgettable.\", \"Super smooth experience.\",\n",
        "    \"I regret buying it.\", \"Truly inspiring.\", \"Boring and repetitive.\",\n",
        "    \"Five stars!\", \"Nothing new.\", \"Highly entertaining.\", \"Wasted potential.\", \"It was alright.\"\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame([(s,) for s in sentences], [\"text\"])\n",
        "\n",
        "# Spark NLP pipeline\n",
        "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        "\n",
        "# Add sentence embeddings\n",
        "use = UniversalSentenceEncoder.pretrained(\"tfhub_use\", \"en\") \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "# Use pretrained sentiment model (Twitter-based)\n",
        "sentiment_model = SentimentDLModel.pretrained(\"sentimentdl_use_twitter\", \"en\")\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"sentiment\")\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = Pipeline(stages=[document_assembler, use, sentiment_model])\n",
        "\n",
        "# Run the pipeline\n",
        "result = pipeline.fit(df).transform(df)\n",
        "\n",
        "# Show results\n",
        "result.select(\"text\", \"sentiment.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9DrHdiVDFhX",
        "outputId": "9b80464f-d77f-4aaa-b466-b0c87c7b26cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "sentimentdl_use_twitter download started this may take some time.\n",
            "Approximate size to download 11.4 MB\n",
            "[OK!]\n",
            "+-------------------------------+----------+\n",
            "|text                           |result    |\n",
            "+-------------------------------+----------+\n",
            "|I love this movie!             |[positive]|\n",
            "|This was the worst experience. |[negative]|\n",
            "|Pretty decent overall.         |[positive]|\n",
            "|Absolutely fantastic!          |[positive]|\n",
            "|I'm not sure how I feel.       |[negative]|\n",
            "|Worst purchase ever.           |[negative]|\n",
            "|Great value for the money.     |[positive]|\n",
            "|It was okay, not great.        |[neutral] |\n",
            "|Terrible, just terrible.       |[negative]|\n",
            "|Super fun and engaging!        |[positive]|\n",
            "|Would not recommend it.        |[negative]|\n",
            "|Kind of boring.                |[negative]|\n",
            "|Loved every minute!            |[positive]|\n",
            "|It was a disaster.             |[negative]|\n",
            "|Highly recommend!              |[positive]|\n",
            "|Too expensive for what you get.|[negative]|\n",
            "|Amazing support team!          |[positive]|\n",
            "|Horrible food.                 |[negative]|\n",
            "|I'll definitely buy it again.  |[positive]|\n",
            "|Meh, nothing special.          |[negative]|\n",
            "+-------------------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison of the Three Approaches**\n",
        "#Traditional Machine Learning Model\n",
        "\n",
        "Workflow:\n",
        "\n",
        "-Started Spark NLP and loaded 50 sample sentences.\n",
        "\n",
        "-Converted text to documents using DocumentAssembler.\n",
        "\n",
        "-Generated sentence embeddings with a pretrained Universal Sentence Encoder (tfhub_use).\n",
        "\n",
        "-Model Classifies sentiment using a pretrained Twitter-based SentimentDLModel.\n",
        "\n",
        "Outputs each sentence with its predicted sentiment (positive, negative, or neutral).\n",
        "\n",
        "Essentially, it’s sentiment analysis on short text using pretrained NLP models.\n",
        "\n",
        "# HuggingFace LLM (GPT-2) Approach\n",
        "\n",
        "Here we are using real-time sentiment analysis inside PySpark using a Hugging Face model via a UDF (User Defined Function):\n",
        "Workflow:\n",
        "-Starting a Spark session.\n",
        "\n",
        "-Loading sample text data into a Spark DataFrame.\n",
        "\n",
        "-Defined a UDF that loads the Hugging Face sentiment-analysis pipeline once (lazy loading) and predicts sentiment for each row.\n",
        "\n",
        "-Applied the UDF to the sentence column to create a predicted_sentiment column.\n",
        "\n",
        "-Displays the results in the Spark directly.\n",
        "\n",
        "It lets Spark run distributed Hugging Face sentiment predictions on text data without converting to Pandas.\n",
        "\n",
        "\n",
        "\n",
        "# Spark NLP Sentiment Analysis  with ROBERTa Model\n",
        "\n",
        "Sentiment analysis evaluation workflow combining PySpark, Hugging Face Transformers, and scikit-learn:\n",
        "\n",
        "-Created sample labeled sentences (positive, negative, neutral).\n",
        "\n",
        "-Started a Spark session and loads the data into a Spark DataFrame.\n",
        "\n",
        "-Converted to Pandas for Hugging Face inference.\n",
        "\n",
        "-Loading a pretrained DistilBERT sentiment model (ROBERTa Model)\n",
        "\n",
        "Predicts sentiment for each sentence and maps it to positive, negative, or neutral.\n",
        "\n",
        "Evaluated  performance using classification report & accuracy score.\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "    negative      0.700     1.000     0.824         7\n",
        "     neutral      0.000     0.000     0.000         4\n",
        "    positive      0.900     1.000     0.947         9\n",
        "\n",
        "    accuracy                          0.800        20\n",
        "   macro avg      0.533     0.667     0.590        20\n",
        "weighted avg      0.650     0.800     0.715        20\n",
        "\n",
        "\n",
        "Accuracy Score: 0.8\n",
        "\n",
        "# Reflection on these approcahes\n",
        "\n",
        "First approach (Spark NLP) feels like the “traditional Spark ML” way — scalable, self-contained, but using older or domain-specific models. It's the most cluster-friendly but possibly the least accurate compared to modern Transformer-based approaches.\n",
        "\n",
        "Second approach (HuggingFace in Pandas) is great for experiments and small datasets because it gives you the latest model power quickly — but you lose Spark's scale. It's the most “ML research notebook” friendly.\n",
        "\n",
        "Third approach (HF RoBERTa in Spark UDF) is the middle ground — keeps Spark's scale, uses cutting-edge models, but needs careful optimization. It's the most production-ready if you want Transformer accuracy and Spark's parallelism.\n",
        "\n",
        "If I had to pick for large-scale production sentiment analysis:\n",
        "\n",
        "I would choose RoBERTa for accuracy and scale,\n",
        "\n",
        "But if speed and simplicity matter more than cutting-edge accuracy, Traditional ML approach with Spark NLP is cleaner.\n",
        "\n",
        "HuggingFacer Model is best for prototyping & evaluation before scaling up.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rgd4DmAYNkku"
      }
    }
  ]
}