{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.mllib.linalg.distributed import RowMatrix\n",
        "from pyspark.mllib.linalg import Vectors as MLLibVectors\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"LSA with SVD\").getOrCreate()\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    (0, \"Spark is a unified analytics engine for big data processing\"),\n",
        "    (1, \"Machine learning is a method of data analysis that automates analytical model building\"),\n",
        "    (2, \"Deep learning models are built using artificial neural networks\"),\n",
        "    (3, \"Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge from data\")\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, [\"id\", \"text\"])\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "words_data = tokenizer.transform(df)\n",
        "\n",
        "# Remove stopwords\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "filtered_data = remover.transform(words_data)\n",
        "\n",
        "# TF\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
        "featurized_data = hashingTF.transform(filtered_data)\n",
        "\n",
        "# IDF\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "idf_model = idf.fit(featurized_data)\n",
        "rescaled_data = idf_model.transform(featurized_data)\n",
        "\n",
        "# Convert to RowMatrix for SVD\n",
        "rows_rdd = rescaled_data.select(\"features\").rdd.map(lambda row: MLLibVectors.fromML(row['features']))\n",
        "mat = RowMatrix(rows_rdd)\n",
        "\n",
        "# Apply SVD\n",
        "svd = mat.computeSVD(2, computeU=True)\n",
        "\n",
        "# Collect U (document-topic matrix)\n",
        "u_rows = svd.U.rows.zipWithIndex().map(lambda row: (row[1], row[0].toArray().tolist()))\n",
        "u_df = spark.createDataFrame(u_rows, [\"id\", \"svd_features\"])\n",
        "\n",
        "# Join back with original text\n",
        "final_df = df.join(u_df, on=\"id\")\n",
        "final_df.select(\"id\", \"text\", \"svd_features\").show(truncate=False)\n",
        "\n",
        "# Convert results to HTML\n",
        "html_output = \"\"\"\n",
        "<html><head><title>LSA Output</title></head><body>\n",
        "<h2>LSA using SVD</h2>\n",
        "<table border=\"1\"><tr><th>ID</th><th>Text</th><th>SVD Features</th></tr>\n",
        "\"\"\"\n",
        "for row in final_df.collect():\n",
        "    html_output += f\"<tr><td>{row['id']}</td><td>{row['text']}</td><td>{row['svd_features']}</td></tr>\\n\"\n",
        "\n",
        "html_output += \"</table></body></html>\"\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYFBL_Q6MIy-",
        "outputId": "d8de05c0-4e5c-4649-b01a-681af2052e57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------+\n",
            "|id |text                                                                                                                                       |svd_features                                 |\n",
            "+---+-------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------+\n",
            "|0  |Spark is a unified analytics engine for big data processing                                                                                |[0.023219821730851027, 0.0024105356152050003]|\n",
            "|1  |Machine learning is a method of data analysis that automates analytical model building                                                     |[0.031357203854802326, 0.15386572241412375]  |\n",
            "|2  |Deep learning models are built using artificial neural networks                                                                            |[0.005042029039510699, 0.9880395281487324]   |\n",
            "|3  |Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge from data|[0.9992257720797436, -0.009870136759833541]  |\n",
            "+---+-------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------+\n",
            "\n",
            "HTML output saved to /tmp/lsa_svd_output.html\n"
          ]
        }
      ]
    }
  ]
}